# ОТЧЕТ по 4-ему этапу.


Что было сделано в рамках нынешнего проекта:

Надо было создать поддержку обработки запросов с уточнением числа необходимых репликаций.

Как это реализовывалось:
* Были заменена обработка запроса: после парсинга числа `ack` и `from`, определялось множество
шардов, на которых, будет выполняться обращения в базу (за это стал ответственен `ClusterManager`) и запускался
синхронный фор, который для каждого из `from` делал новый запрос с добавления хедера `Inner: True`, который
означает, что запрос надо сделать у себя локально. Если запрос приходил без этого хедера, то отправлялся в
`internalRequestService` а иначе в `executorService`.
* В случае координатора, то координатор в рамках упомянутого фора делал запрос на все необходимые шарды,
дожидался от них респонса (или обортил, если запрос выходил за таймаут), и собирал число успешных запросов,
сравнил их с числом нужных (`ack`) и отправлял соответсвующий обработке ответ. В случае гета он также судил по
временам пришедших запросов, брал самый свежий ответ и делал вывод по нему.
* Перед фором он делал таймстемп и в запрос прописывал его в качестве хедера, чтобы когда обработчик
ответов `ResponseManager` (вообще он обработчик запросов, но назван так, так как он всегда возвращает респонсы) 
вписывал время в базу вместе с данными. Данные стали хранится в виде `[status][timestamp][data]`, и удаление превратилось
в замену значения на томбстоун, то есть данные вида `[0xFF][timestamp][]`, если данные нормальны, то `status = 0x00`.
* При гете также берется таймстепм из данных и записывается в качестве хедера в репонс.